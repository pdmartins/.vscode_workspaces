---
name: code-skill-evaluate
description: Avalia a efic√°cia de skills via cen√°rios estruturados (YAML) usando o pr√≥prio GHCP como juiz. Testa routing accuracy (skill correta ativada?), output quality (segue template? √© √∫til?) e anti-hallucination (inventa dados n√£o ancorados?). L√™ cen√°rios do test project (_test/llm-judge), simula comportamento, auto-avalia contra rubrics, e registra findings. Triggers: "avaliar skill", "testar skill", "LLM judge", "evaluate skill", "rodar avalia√ß√£o", "skill evaluation", "validar efic√°cia".
metadata:
  author: copilot-core
  version: "1.0"
  category: code
  delegable: orchestrated
---

# Code Skill Evaluate

Avalia skills do `.copilot-core` usando cen√°rios estruturados e auto-avalia√ß√£o LLM.

## Quando Usar

- Ap√≥s criar ou alterar uma skill significativamente
- Avalia√ß√£o peri√≥dica de qualidade dos prompts
- Usu√°rio pede "avaliar skill", "testar skill", "LLM judge"
- Antes de release de novas vers√µes do core

## Quando N√ÉO Usar

- Para testes estruturais (pytest j√° cobre: frontmatter, naming, size)
- Para validar schema dos cen√°rios YAML (pytest `@pytest.mark.evaluation` cobre)
- Para criar cen√°rios (usar editor normal)

## Config Loading

1. Verificar worktree: `{workspace}/.copilot-project-worktrees/_test/llm-judge/`
2. Carregar `skills/code-skill-evaluate/config.yml` para thresholds e weights
3. Listar cen√°rios em `scenarios/{tipo}/` para descobrir dispon√≠veis

## Workflow

### 1. Selecionar cen√°rios

```
Op√ß√µes:
a) Avaliar skill espec√≠fica ‚Üí filtrar cen√°rios que referenciam a skill
b) Avaliar por tipo ‚Üí routing | quality | hallucination
c) Avaliar todos ‚Üí batch completo
d) Avaliar cen√°rio espec√≠fico ‚Üí por nome de arquivo
```

**Input do usu√°rio**: qual skill ou tipo avaliar.

### 2. Carregar cen√°rio

Para cada cen√°rio YAML selecionado:

```yaml
# Campos a extrair:
scenario:          # t√≠tulo
evaluation_type:   # routing | quality | hallucination
user_message:      # mensagem simulada do usu√°rio
context:           # contexto simulado do projeto
target_skill:      # (quality/hallucination) skill alvo
expected_skills:   # (routing) skills esperadas
rubric:            # crit√©rios weighted
grounding:         # (hallucination) √¢ncoras permitidas e proibidas
```

### 3. Avaliar ‚Äî por tipo

#### Routing

Para cada cen√°rio de routing:

1. Ler `user_message` e `context`
2. Considerar as instructions globais + skills carregados
3. **Determinar**: qual skill(s) o agente ativaria?
4. **Comparar** com `expected_skills`:
   - `must_activate: true` ‚Üí skill DEVE ser escolhida
   - `must_activate: false` ‚Üí skill N√ÉO deve ser escolhida
5. **Score**: 5 (match perfeito), 3 (parcial ‚Äî ativou correta mas tamb√©m incorreta), 0 (ativou errada)

#### Quality

Para cada cen√°rio de quality:

1. Ler `user_message`, `context`, `target_skill`
2. Carregar SKILL.md da `target_skill`
3. **Simular**: que output o agente geraria seguindo este SKILL.md?
4. **Avaliar** cada crit√©rio do `rubric`:
   - Score 0-5 com justificativa de uma linha
   - Peso do crit√©rio aplicado ao c√°lculo
5. **Score**: m√©dia ponderada dos crit√©rios

#### Hallucination

Para cada cen√°rio de hallucination:

1. Ler `user_message`, `context`, `target_skill`, `grounding`
2. Carregar SKILL.md da `target_skill`
3. **Simular**: que output o agente geraria?
4. **Verificar cada crit√©rio** do rubric (type: hallucination):
   - O output cont√©m claims N√ÉO ancoradas nos `allowed_sources`?
   - O output viola algum `forbidden_claims`?
5. **Score**: 5 (zero hallucination), 3 (minor ‚Äî sugest√£o vs afirma√ß√£o), 0 (hallucination factual)

### 4. Registrar resultado

Para cada cen√°rio avaliado, registrar via `agent-memory-update` no test project:

- **Categoria**: `decisions`
- **Arquivo**: `memory/decisions/eval-{scenario-slug}.md`
- **Conte√∫do**: Cen√°rio, skill avaliado, tipo, score, crit√©rios individuais, resultado (PASS/FAIL)

### 5. Resumo da sess√£o

Ap√≥s avaliar todos os cen√°rios da sess√£o:

```
üìä **Avalia√ß√£o conclu√≠da**

| Tipo | Cen√°rios | Avg Score | Pass Rate |
|------|----------|-----------|-----------|
| Routing | N | X.X/5.0 | Y% |
| Quality | N | X.X/5.0 | Y% |
| Hallucination | N | X.X/5.0 | Y% |
| **Total** | **N** | **X.X/5.0** | **Y%** |

Pass threshold: {pass_threshold} (from config.yml)

{lista de cen√°rios que falharam com brief reason}
```

## Schema dos Cen√°rios

### Routing

```yaml
scenario: "Human-readable title"
evaluation_type: routing
difficulty: easy | medium | hard

user_message: "frase que o usu√°rio diria"
context:
  project_stack: ["tech", "version"]
  existing_files: ["path/to/file"]
  has_copilot_project: true | false  # optional

expected_skills:
  - name: skill-name
    must_activate: true | false
    reason: "why"

notes: "optional clarification"
```

### Quality

```yaml
scenario: "Human-readable title"
evaluation_type: quality
difficulty: easy | medium | hard

user_message: "frase que o usu√°rio diria"
context:
  project_stack: ["tech", "version"]
  existing_files: ["path/to/file"]

target_skill: skill-name

rubric:
  - criterion: "what to evaluate"
    weight: 1-5
  - criterion: "another criterion"
    weight: 1-5
```

### Hallucination

```yaml
scenario: "Human-readable title"
evaluation_type: hallucination
difficulty: easy | medium | hard

user_message: "frase que o usu√°rio diria"
context:
  project_stack: ["tech", "version"]
  existing_files: ["path/to/file"]
  code_snippet: |  # optional ‚Äî actual code to review
    ...

target_skill: skill-name

grounding:
  allowed_sources:
    - "skill-name/SKILL.md"
    - "Project context description"
  forbidden_claims:
    - "Specific fabrication to watch for"

rubric:
  - criterion: "what to check"
    weight: 1-5
    type: hallucination | quality
```

## Regras

1. **Honestidade**: Avaliar com rigor ‚Äî n√£o inflar scores
2. **Justificativa**: Todo score precisa de justificativa de uma linha
3. **Isolamento**: Registrar findings APENAS no test project (`_test/llm-judge`)
4. **Reproducibilidade**: Anotar se o resultado pode variar entre runs
5. **Actionable**: Findings devem sugerir melhorias concretas na skill avaliada

## Checklist

- [ ] Cen√°rio YAML lido e validado
- [ ] SKILL.md da skill alvo carregado
- [ ] Avalia√ß√£o executada por tipo (routing/quality/hallucination)
- [ ] Score calculado com justificativas
- [ ] Resultado registrado via `agent-memory-update` (categoria: decisions)
- [ ] Resumo da sess√£o apresentado ao usu√°rio
